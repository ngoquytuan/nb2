Ph√¢n t√≠ch r·∫•t t·ªët! T√¥i s·∫Ω ƒë∆∞a ra l·ªô tr√¨nh c·∫£i thi·ªán c√°c v·∫•n ƒë·ªÅ n√†y:

## üéØ L·ªô tr√¨nh c·∫£i thi·ªán

### Phase 1: C·∫£i thi·ªán LLM Connection & Error Handling
### Phase 2: Dynamic Configuration UI  
### Phase 3: Enhanced Mock System v·ªõi Scoring

---

## üìç Phase 1: LLM Connection Transparency

### 1.1 T·∫°o LLM Health Monitor (models/llm_health.py)

```python
import time
import requests
from enum import Enum
from typing import Dict, Optional
from datetime import datetime, timedelta

class LLMProviderStatus(Enum):
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    DOWN = "down"
    UNKNOWN = "unknown"

class LLMHealthMonitor:
    def __init__(self):
        self.last_checks = {}
        self.status_cache = {}
        self.error_counts = {}
        self.response_times = {}
        
    def check_provider_health(self, provider: str, api_key: str) -> Dict:
        """Ki·ªÉm tra health c·ªßa LLM provider"""
        start_time = time.time()
        
        try:
            if provider == 'openai':
                result = self._check_openai_health(api_key)
            elif provider == 'groq':
                result = self._check_groq_health(api_key)
            elif provider == 'openrouter':
                result = self._check_openrouter_health(api_key)
            else:
                result = {
                    'status': LLMProviderStatus.UNKNOWN,
                    'error': f'Unknown provider: {provider}',
                    'details': {}
                }
                
        except Exception as e:
            result = {
                'status': LLMProviderStatus.DOWN,
                'error': str(e),
                'details': {'exception_type': type(e).__name__}
            }
        
        # T√≠nh response time
        response_time = (time.time() - start_time) * 1000
        result['response_time_ms'] = response_time
        result['checked_at'] = datetime.now().isoformat()
        
        # Update cache
        self.status_cache[provider] = result
        self.last_checks[provider] = datetime.now()
        
        return result
    
    def _check_openai_health(self, api_key: str) -> Dict:
        """Health check cho OpenAI"""
        url = "https://api.openai.com/v1/models"
        headers = {"Authorization": f"Bearer {api_key}"}
        
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            models = response.json().get('data', [])
            available_models = [m['id'] for m in models if 'gpt' in m['id']]
            
            return {
                'status': LLMProviderStatus.HEALTHY,
                'details': {
                    'available_models': available_models[:5],  # Ch·ªâ l·∫•y 5 model ƒë·∫ßu
                    'total_models': len(available_models)
                }
            }
        elif response.status_code == 401:
            return {
                'status': LLMProviderStatus.DOWN,
                'error': 'Invalid API key',
                'details': {'status_code': 401}
            }
        else:
            return {
                'status': LLMProviderStatus.DEGRADED,
                'error': f'HTTP {response.status_code}: {response.text[:100]}',
                'details': {'status_code': response.status_code}
            }
    
    def _check_groq_health(self, api_key: str) -> Dict:
        """Health check cho Groq"""
        url = "https://api.groq.com/openai/v1/models"
        headers = {"Authorization": f"Bearer {api_key}"}
        
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            models = response.json().get('data', [])
            return {
                'status': LLMProviderStatus.HEALTHY,
                'details': {
                    'available_models': [m['id'] for m in models][:3],
                    'total_models': len(models)
                }
            }
        elif response.status_code == 401:
            return {
                'status': LLMProviderStatus.DOWN,
                'error': 'Invalid API key',
                'details': {'status_code': 401}
            }
        else:
            return {
                'status': LLMProviderStatus.DEGRADED,
                'error': f'HTTP {response.status_code}',
                'details': {'status_code': response.status_code}
            }
    
    def _check_openrouter_health(self, api_key: str) -> Dict:
        """Health check cho OpenRouter"""
        url = "https://openrouter.ai/api/v1/models"
        headers = {"Authorization": f"Bearer {api_key}"}
        
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            return {
                'status': LLMProviderStatus.HEALTHY,
                'details': {'models_endpoint': 'accessible'}
            }
        else:
            return {
                'status': LLMProviderStatus.DEGRADED,
                'error': f'HTTP {response.status_code}',
                'details': {'status_code': response.status_code}
            }
    
    def get_cached_status(self, provider: str) -> Optional[Dict]:
        """L·∫•y status ƒë√£ cache (trong v√≤ng 5 ph√∫t)"""
        if provider not in self.last_checks:
            return None
            
        if datetime.now() - self.last_checks[provider] < timedelta(minutes=5):
            return self.status_cache.get(provider)
            
        return None
```

### 1.2 C·∫≠p nh·∫≠t LLM Analyzer v·ªõi Error Tracking (models/llm_analyzer.py)

```python
# Th√™m v√†o ƒë·∫ßu file
from .llm_health import LLMHealthMonitor, LLMProviderStatus

class LLMAnalyzer:
    def __init__(self):
        self.config = Config()
        self.provider = self.config.LLM_PROVIDER.lower()
        self.health_monitor = LLMHealthMonitor()
        self.error_log = []
    
    def analyze_message(self, message: str) -> dict:
        """Ph√¢n t√≠ch message v·ªõi error tracking chi ti·∫øt"""
        start_time = time.time()
        
        # Check provider health tr∆∞·ªõc khi g·ªçi
        health_status = self._check_provider_health()
        
        result = {
            'provider': self.provider,
            'health_status': health_status,
            'processing_time_ms': 0,
            'error_details': None
        }
        
        try:
            if health_status['status'] != LLMProviderStatus.HEALTHY:
                # Fallback to mock n·∫øu provider kh√¥ng healthy
                analysis = self._enhanced_mock_analysis(message)
                result.update({
                    'fallback_reason': f"Provider {self.provider} is {health_status['status'].value}",
                    **analysis
                })
            else:
                # Th·ª≠ g·ªçi LLM th·ª±c
                if self.provider == 'openai':
                    analysis = self._analyze_with_openai(message)
                elif self.provider == 'groq':
                    analysis = self._analyze_with_groq(message)
                elif self.provider == 'openrouter':
                    analysis = self._analyze_with_openrouter(message)
                else:
                    analysis = self._enhanced_mock_analysis(message)
                
                result.update(analysis)
                
        except requests.exceptions.Timeout as e:
            self._log_error('timeout', str(e))
            result.update({
                'error_details': {
                    'type': 'timeout',
                    'message': 'LLM request timed out',
                    'provider': self.provider
                },
                **self._enhanced_mock_analysis(message, fallback=True)
            })
            
        except requests.exceptions.ConnectionError as e:
            self._log_error('connection', str(e))
            result.update({
                'error_details': {
                    'type': 'connection',
                    'message': 'Cannot connect to LLM provider',
                    'provider': self.provider
                },
                **self._enhanced_mock_analysis(message, fallback=True)
            })
            
        except requests.exceptions.HTTPError as e:
            self._log_error('http', str(e))
            result.update({
                'error_details': {
                    'type': 'http',
                    'message': f'HTTP error: {e.response.status_code}',
                    'provider': self.provider,
                    'status_code': e.response.status_code
                },
                **self._enhanced_mock_analysis(message, fallback=True)
            })
            
        except Exception as e:
            self._log_error('unknown', str(e))
            result.update({
                'error_details': {
                    'type': 'unknown',
                    'message': str(e),
                    'provider': self.provider
                },
                **self._enhanced_mock_analysis(message, fallback=True)
            })
        
        result['processing_time_ms'] = (time.time() - start_time) * 1000
        return result
    
    def _check_provider_health(self) -> Dict:
        """Ki·ªÉm tra health c·ªßa provider hi·ªán t·∫°i"""
        # L·∫•y t·ª´ cache n·∫øu c√≥
        cached = self.health_monitor.get_cached_status(self.provider)
        if cached:
            return cached
            
        # Ki·ªÉm tra m·ªõi
        api_key = self._get_api_key()
        if not api_key or api_key.startswith('your-'):
            return {
                'status': LLMProviderStatus.DOWN,
                'error': 'No valid API key configured'
            }
            
        return self.health_monitor.check_provider_health(self.provider, api_key)
    
    def _get_api_key(self) -> str:
        """L·∫•y API key theo provider"""
        if self.provider == 'openai':
            return self.config.OPENAI_API_KEY
        elif self.provider == 'groq':
            return self.config.GROQ_API_KEY
        elif self.provider == 'openrouter':
            return self.config.OPENROUTER_API_KEY
        return ""
    
    def _log_error(self, error_type: str, message: str):
        """Log l·ªói ƒë·ªÉ tracking"""
        self.error_log.append({
            'timestamp': datetime.now().isoformat(),
            'type': error_type,
            'message': message,
            'provider': self.provider
        })
        
        # Ch·ªâ gi·ªØ 50 errors g·∫ßn nh·∫•t
        if len(self.error_log) > 50:
            self.error_log = self.error_log[-50:]
    
    def get_error_summary(self) -> Dict:
        """T·ªïng h·ª£p l·ªói trong 24h qua"""
        now = datetime.now()
        recent_errors = [
            err for err in self.error_log 
            if (now - datetime.fromisoformat(err['timestamp'])).total_seconds() < 86400
        ]
        
        error_counts = {}
        for err in recent_errors:
            error_counts[err['type']] = error_counts.get(err['type'], 0) + 1
        
        return {
            'total_errors_24h': len(recent_errors),
            'error_breakdown': error_counts,
            'recent_errors': recent_errors[-5:]  # 5 l·ªói g·∫ßn nh·∫•t
        }
```

### 1.3 Enhanced Mock Analysis

```python
# Th√™m v√†o LLM Analyzer
def _enhanced_mock_analysis(self, message: str, fallback: bool = False) -> dict:
    """Mock analysis v·ªõi scoring chi ti·∫øt"""
    message_lower = message.lower()
    
    # Ph√¢n t√≠ch t·ª´ kh√≥a v·ªõi tr·ªçng s·ªë
    spam_keywords = {
        'tr√∫ng gi·∫£i': 0.9,
        'vay ti·ªÅn': 0.8, 
        'khuy·∫øn m√£i': 0.7,
        'mi·ªÖn ph√≠': 0.6,
        'click link': 0.9,
        'chuy·ªÉn kho·∫£n': 0.8,
        'm√£ otp': 0.9,
        'x√°c th·ª±c': 0.7,
        'l√†m gi√†u': 0.8,
        'ƒë·∫ßu t∆∞': 0.6,
        'l·ª£i nhu·∫≠n': 0.7,
        'c·∫£nh b√°o': 0.8,
        't√†i kho·∫£n b·ªã kh√≥a': 0.9,
        'nh·∫•p v√†o ƒë√¢y': 0.8
    }
    
    legitimate_keywords = {
        'xin ch√†o': 0.3,
        'c·∫£m ∆°n': 0.2,
        'meeting': 0.2,
        'd·ª± √°n': 0.2,
        'b√°o c√°o': 0.2,
        'c√¥ng ty': 0.3,
        'h·ªó tr·ª£': 0.3,
        'th√¥ng tin': 0.4
    }
    
    # T√≠nh ƒëi·ªÉm spam
    spam_score = 0.0
    matched_spam_keywords = []
    for keyword, weight in spam_keywords.items():
        if keyword in message_lower:
            spam_score += weight
            matched_spam_keywords.append(keyword)
    
    # T√≠nh ƒëi·ªÉm legitimate  
    legit_score = 0.0
    matched_legit_keywords = []
    for keyword, weight in legitimate_keywords.items():
        if keyword in message_lower:
            legit_score += weight
            matched_legit_keywords.append(keyword)
    
    # Normalize scores
    spam_score = min(spam_score, 1.0)
    legit_score = min(legit_score, 1.0)
    
    # Final decision
    if spam_score >= 0.8:
        classification = 'spam'
        is_spam = True
        confidence = 0.85 + (spam_score - 0.8) * 0.15
    elif spam_score >= 0.5:
        classification = 'suspicious' 
        is_spam = False
        confidence = 0.6 + (spam_score - 0.5) * 0.3
    elif legit_score >= 0.4:
        classification = 'legitimate'
        is_spam = False
        confidence = 0.7 + legit_score * 0.3
    else:
        classification = 'suspicious'
        is_spam = False
        confidence = 0.5
    
    # T·∫°o reason chi ti·∫øt
    reason_parts = []
    if matched_spam_keywords:
        reason_parts.append(f"Ph√°t hi·ªán t·ª´ kh√≥a spam: {', '.join(matched_spam_keywords)}")
    if matched_legit_keywords:
        reason_parts.append(f"Ph√°t hi·ªán t·ª´ kh√≥a h·ª£p l·ªá: {', '.join(matched_legit_keywords)}")
    
    reason = f"Mock Analysis: {'. '.join(reason_parts) if reason_parts else 'Kh√¥ng ph√°t hi·ªán t·ª´ kh√≥a ƒë·∫∑c bi·ªát'}"
    
    if fallback:
        reason = f"LLM Fallback - {reason}"
    
    return {
        'is_spam': is_spam,
        'confidence': round(confidence, 3),
        'reason': reason,
        'classification': classification,
        'analysis_method': 'enhanced_mock',
        'scoring_details': {
            'spam_score': round(spam_score, 3),
            'legitimate_score': round(legit_score, 3),
            'matched_spam_keywords': matched_spam_keywords,
            'matched_legit_keywords': matched_legit_keywords
        }
    }
```

---

## üìç Phase 2: Dynamic Configuration UI

### 2.1 Database Schema cho Settings (database/db_manager.py)

```python
# Th√™m v√†o init_database()
def init_database(self):
    """Kh·ªüi t·∫°o database v√† c√°c b·∫£ng"""
    conn = sqlite3.connect(self.db_path)
    cursor = conn.cursor()
    
    # ... existing tables ...
    
    # B·∫£ng system settings
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS system_settings (
            key TEXT PRIMARY KEY,
            value TEXT NOT NULL,
            data_type TEXT DEFAULT 'string',
            description TEXT,
            category TEXT DEFAULT 'general',
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # Insert default settings n·∫øu ch∆∞a c√≥
    default_settings = [
        ('llm_provider', 'openai', 'string', 'LLM Provider (openai/groq/openrouter)', 'llm'),
        ('openai_api_key', '', 'password', 'OpenAI API Key', 'llm'),
        ('groq_api_key', '', 'password', 'Groq API Key', 'llm'), 
        ('openrouter_api_key', '', 'password', 'OpenRouter API Key', 'llm'),
        ('naive_bayes_threshold', '0.7', 'float', 'Ng∆∞·ª°ng confidence cho Naive Bayes', 'filter'),
        ('suspicious_threshold', '0.5', 'float', 'Ng∆∞·ª°ng ƒë√°nh d·∫•u suspicious', 'filter'),
        ('enable_mock_fallback', 'true', 'boolean', 'B·∫≠t mock analysis khi LLM l·ªói', 'system'),
        ('max_processing_time', '30', 'int', 'Timeout t·ªëi ƒëa (gi√¢y)', 'system'),
        ('enable_health_check', 'true', 'boolean', 'B·∫≠t ki·ªÉm tra health LLM', 'system')
    ]
    
    for key, value, data_type, desc, category in default_settings:
        cursor.execute('''
            INSERT OR IGNORE INTO system_settings 
            (key, value, data_type, description, category) 
            VALUES (?, ?, ?, ?, ?)
        ''', (key, value, data_type, desc, category))
    
    conn.commit()
    conn.close()

# Th√™m methods cho settings
def get_setting(self, key: str, default=None):
    """L·∫•y gi√° tr·ªã setting"""
    conn = sqlite3.connect(self.db_path)
    cursor = conn.cursor()
    
    cursor.execute("SELECT value, data_type FROM system_settings WHERE key = ?", (key,))
    result = cursor.fetchone()
    conn.close()
    
    if not result:
        return default
        
    value, data_type = result
    
    # Convert theo data type
    if data_type == 'int':
        return int(value)
    elif data_type == 'float':
        return float(value)
    elif data_type == 'boolean':
        return value.lower() in ('true', '1', 'yes')
    else:
        return value

def update_setting(self, key: str, value: str):
    """C·∫≠p nh·∫≠t setting"""
    conn = sqlite3.connect(self.db_path)
    cursor = conn.cursor()
    
    cursor.execute('''
        UPDATE system_settings 
        SET value = ?, updated_at = CURRENT_TIMESTAMP 
        WHERE key = ?
    ''', (str(value), key))
    
    conn.commit()
    conn.close()

def get_all_settings(self) -> Dict:
    """L·∫•y t·∫•t c·∫£ settings theo category"""
    conn = sqlite3.connect(self.db_path)
    conn.row_factory = sqlite3.Row
    cursor = conn.cursor()
    
    cursor.execute("SELECT * FROM system_settings ORDER BY category, key")
    rows = cursor.fetchall()
    conn.close()
    
    settings = {}
    for row in rows:
        category = row['category']
        if category not in settings:
            settings[category] = []
            
        settings[category].append({
            'key': row['key'],
            'value': row['value'],
            'data_type': row['data_type'],
            'description': row['description'],
            'updated_at': row['updated_at']
        })
    
    return settings
```

### 2.2 Dynamic Config Class (config.py)

```python
class DynamicConfig:
    def __init__(self, db_manager):
        self.db = db_manager
        self._cache = {}
        self._cache_time = {}
        self.CACHE_DURATION = 300  # 5 ph√∫t
    
    def get(self, key: str, default=None):
        """L·∫•y config v·ªõi caching"""
        now = time.time()
        
        # Check cache
        if (key in self._cache and 
            key in self._cache_time and 
            now - self._cache_time[key] < self.CACHE_DURATION):
            return self._cache[key]
        
        # Get from DB
        value = self.db.get_setting(key, default)
        
        # Cache result
        self._cache[key] = value
        self._cache_time[key] = now
        
        return value
    
    def update(self, key: str, value):
        """Update config v√† clear cache"""
        self.db.update_setting(key, value)
        
        # Clear cache for this key
        if key in self._cache:
            del self._cache[key]
        if key in self._cache_time:
            del self._cache_time[key]
    
    def clear_cache(self):
        """Clear to√†n b·ªô cache"""
        self._cache = {}
        self._cache_time = {}
    
    # Properties ƒë·ªÉ t∆∞∆°ng th√≠ch v·ªõi code c≈©
    @property
    def LLM_PROVIDER(self):
        return self.get('llm_provider', 'openai')
    
    @property
    def OPENAI_API_KEY(self):
        return self.get('openai_api_key', '')
    
    @property
    def GROQ_API_KEY(self):
        return self.get('groq_api_key', '')
        
    @property
    def OPENROUTER_API_KEY(self):
        return self.get('openrouter_api_key', '')
    
    @property
    def NAIVE_BAYES_THRESHOLD(self):
        return self.get('naive_bayes_threshold', 0.7)
    
    @property 
    def SUSPICIOUS_THRESHOLD(self):
        return self.get('suspicious_threshold', 0.5)
```

### 2.3 Settings API Routes (app.py)

```python
# Th√™m v√†o app.py
@app.route('/api/settings')
def get_settings():
    """L·∫•y t·∫•t c·∫£ settings"""
    settings = db.get_all_settings()
    
    # Mask passwords
    for category in settings:
        for setting in settings[category]:
            if setting['data_type'] == 'password' and setting['value']:
                setting['value'] = '***masked***'
    
    return jsonify(settings)

@app.route('/api/settings', methods=['POST'])
def update_settings():
    """C·∫≠p nh·∫≠t settings"""
    data = request.json
    updated_keys = []
    
    for key, value in data.items():
        # Validate key exists
        current = db.get_setting(key)
        if current is not None:
            db.update_setting(key, value)
            updated_keys.append(key)
            
            # Clear config cache
            if hasattr(app, 'dynamic_config'):
                app.dynamic_config.clear_cache()
    
    return jsonify({
        'success': True,
        'updated_keys': updated_keys,
        'message': f'Updated {len(updated_keys)} settings'
    })

@app.route('/api/llm/health')
def check_llm_health():
    """Ki·ªÉm tra health c·ªßa LLM providers"""
    provider = app.dynamic_config.LLM_PROVIDER
    
    health_result = llm_analyzer.health_monitor.check_provider_health(
        provider, 
        app.dynamic_config.get(f'{provider}_api_key', '')
    )
    
    # Th√™m error summary
    error_summary = llm_analyzer.get_error_summary()
    
    return jsonify({
        'current_provider': provider,
        'health': health_result,
        'error_summary': error_summary
    })

@app.route('/api/llm/test', methods=['POST'])
def test_llm_connection():
    """Test LLM connection v·ªõi message m·∫´u"""
    data = request.json
    test_message = data.get('message', 'This is a test message.')
    
    result = llm_analyzer.analyze_message(test_message)
    
    return jsonify({
        'success': True,
        'test_result': result,
        'provider': app.dynamic_config.LLM_PROVIDER
    })
```

### 2.4 Settings UI (static/settings.html)

```html
<!-- Th√™m tab Settings v√†o index.html -->
<button class="tab-button" onclick="showTab('settings')">
    ‚öôÔ∏è Settings
</button>

<!-- Tab content -->
<div id="settings-tab" class="tab-content">
    <h3>‚öôÔ∏è System Configuration</h3>
    
    <!-- LLM Settings -->
    <div class="settings-section">
        <h4>ü§ñ LLM Configuration</h4>
        <div class="settings-grid">
            <div class="setting-item">
                <label for="llm_provider">Provider:</label>
                <select id="llm_provider" name="llm_provider">
                    <option value="openai">OpenAI</option>
                    <option value="groq">Groq</option>
                    <option value="openrouter">OpenRouter</option>
                </select>
            </div>
            
            <div class="setting-item">
                <label for="openai_api_key">OpenAI API Key:</label>
                <input type="password" id="openai_api_key" name="openai_api_key" 
                       placeholder="sk-...">
                <button type="button" class="btn btn-small btn-info" 
                        onclick="testLLMConnection('openai')">Test</button>
            </div>
            
            <div class="setting-item">
                <label for="groq_api_key">Groq API Key:</label>
                <input type="password" id="groq_api_key" name="groq_api_key" 
                       placeholder="gsk_...">
                <button type="button" class="btn btn-small btn-info" 
                        onclick="testLLMConnection('groq')">Test</button>
            </div>
            
            <div class="setting-item">
                <label for="openrouter_api_key">OpenRouter API Key:</label>
                <input type="password" id="openrouter_api_key" name="openrouter_api_key" 
                       placeholder="sk-or-...">
                <button type="button" class="btn btn-small btn-info" 
                        onclick="testLLMConnection('openrouter')">Test</button>
            </div>
        </div>
        
        <!-- LLM Health Status -->
        <div class="health-status" id="llmHealthStatus">
            <h5>Provider Health Status</h5>
            <div id="healthStatusContent">
                <p class="loading">Checking...</p>
            </div>
        </div>
    </div>
    
    <!-- Filter Settings -->
    <div class="settings-section">
        <h4>üîç Filter Configuration</h4>
        <div class="settings-grid">
            <div class="setting-item">
                <label for="naive_bayes_threshold">Naive Bayes Threshold:</label>
                <input type="range" id="naive_bayes_threshold" name="naive_bayes_threshold" 
                       min="0.1" max="1.0" step="0.1">
                <span class="range-value" id="nb_threshold_value">0.7</span>
            </div>
            
            <div class="setting-item">
                <label for="suspicious_threshold">Suspicious Threshold:</label>
                <input type="range" id="suspicious_threshold" name="suspicious_threshold" 
                       min="0.1" max="1.0" step="0.1">
                <span class="range-value" id="sus_threshold_value">0.5</span>
            </div>
        </div>
    </div>
    
    <!-- System Settings -->
    <div class="settings-section">
        <h4>üîß System Settings</h4>
        <div class="settings-grid">
            <div class="setting-item">
                <label>
                    <input type="checkbox" id="enable_mock_fallback" name="enable_mock_fallback" checked>
                    Enable Mock Fallback
                </label>
                <small>Use enhanced mock analysis when LLM fails</small>
            </div>
            
            <div class="setting-item">
                <label>
                    <input type="checkbox" id="enable_health_check" name="enable_health_check" checked>
                    Enable Health Monitoring
                </label>
                <small>Automatically check LLM provider health</small>
            </div>
        </div>
    </div>
    
    <!-- Action Buttons -->
    <div class="settings-actions">
        <button class="btn btn-primary" onclick="saveSettings()">
            üíæ Save Settings
        </button>
        <button class="btn btn-info" onclick="loadSettings()">
            üîÑ Reload Settings
        </button>
        <button class="btn btn-warning" onclick="testCurrentLLM()">
            üß™ Test Current LLM
        </button>
    </div>
</div>
```

Ph·∫ßn ti·∫øp theo s·∫Ω bao g·ªìm CSS styling cho settings UI v√† JavaScript functions. B·∫°n c√≥ mu·ªën t√¥i ti·∫øp t·ª•c v·ªõi Phase 3 (Enhanced Mock System) hay ho√†n thi·ªán Phase 2 tr∆∞·ªõc?

Ch·∫Øc ch·∫Øn r·ªìi. D·ª±a tr√™n c√°c file m√£ ngu·ªìn b·∫°n ƒë√£ cung c·∫•p, ch√∫ng ta c√≥ th·ªÉ ph√¢n t√≠ch v√† t√¨m ra nhi·ªÅu h∆∞·ªõng ƒë·ªÉ c·∫£i thi·ªán thu·∫≠t to√°n x·ª≠ l√Ω spam.

Tr∆∞·ªõc h·∫øt, h√£y l√†m r√µ hai nh·∫≠n ƒë·ªãnh c·ªßa b·∫°n:

1.  **"Hi·ªán nay l√† x·ª≠ l√Ω d·ª±a tr√™n keyword l√† ch√≠nh ƒë√∫ng kh√¥ng?"** -> **Ch∆∞a ho√†n to√†n ch√≠nh x√°c.** H·ªá th·ªëng c·ªßa b·∫°n c√≥ 2 l·ªõp x·ª≠ l√Ω ch√≠nh:
    * **Naive Bayes (NB):** L·ªõp n√†y **kh√¥ng** ch·ªâ d·ª±a v√†o t·ª´ kh√≥a. N√≥ s·ª≠ d·ª•ng m√¥ h√¨nh th·ªëng k√™ **TF-IDF** ƒë·ªÉ t√≠nh to√°n "tr·ªçng s·ªë" c·ªßa c√°c t·ª´ v√† c·ª•m t·ª´ (n-gram) d·ª±a tr√™n t·∫ßn su·∫•t xu·∫•t hi·ªán c·ªßa ch√∫ng trong d·ªØ li·ªáu spam v√† kh√¥ng spam. ƒê√¢y l√† ph∆∞∆°ng ph√°p ph·ª©c t·∫°p h∆°n vi·ªác ch·ªâ t√¨m ki·∫øm t·ª´ kh√≥a.
    * **LLM Analyzer:** Khi g·ªçi ƒë·∫øn c√°c API th·∫≠t (OpenAI, Groq), LLM s·∫Ω ph√¢n t√≠ch **ng·ªØ c·∫£nh, √Ω ƒë·ªãnh, v√† c·∫•u tr√∫c c√¢u** ch·ª© kh√¥ng ch·ªâ t·ª´ kh√≥a. L·ªõp x·ª≠ l√Ω d·ª±a tr√™n t·ª´ kh√≥a (`_enhanced_mock_analysis`) th·ª±c ch·∫•t ch·ªâ l√† m·ªôt c∆° ch·∫ø **d·ª± ph√≤ng (fallback)** ho·∫∑c **demo** khi kh√¥ng c√≥ API key ho·∫∑c API b·ªã l·ªói.

2.  **"NB ƒë√£ ph√°t huy h·∫øt kh·∫£ nƒÉng c·ªßa n√≥ ch∆∞a?"** -> **Ch∆∞a, c√≤n r·∫•t nhi·ªÅu kh√¥ng gian ƒë·ªÉ c·∫£i thi·ªán.** Model NB hi·ªán t·∫°i ƒëang d√πng m·ªôt b·ªô d·ªØ li·ªáu m·∫´u kh√° nh·ªè v√† c√°c k·ªπ thu·∫≠t x·ª≠ l√Ω c∆° b·∫£n.

---

### ## C√°c h∆∞·ªõng c·∫£i thi·ªán thu·∫≠t to√°n

D∆∞·ªõi ƒë√¢y l√† nh·ªØng v·ªã tr√≠ b·∫°n c√≥ th·ªÉ t·∫≠p trung c·∫£i thi·ªán, chia theo t·ª´ng th√†nh ph·∫ßn c·ªßa h·ªá th·ªëng.

### 1. C·∫£i thi·ªán Model Naive Bayes (L·ªõp ph√≤ng th·ªß ƒë·∫ßu ti√™n) üõ°Ô∏è

ƒê√¢y l√† l·ªõp quan tr·ªçng v√¨ n√≥ gi√∫p gi·∫£m t·∫£i cho LLM. M·ªôt model NB t·ªët s·∫Ω x·ª≠ l√Ω ƒë∆∞·ª£c ph·∫ßn l·ªõn c√°c tin nh·∫Øn r√µ r√†ng, ch·ªâ ƒë·ªÉ l·∫°i c√°c ca kh√≥ cho LLM.

* **D·ªØ li·ªáu, D·ªØ li·ªáu v√† D·ªØ li·ªáu:** ƒê√¢y l√† y·∫øu t·ªë **quan tr·ªçng nh·∫•t**.
    * **TƒÉng k√≠ch th∆∞·ªõc Dataset:** B·ªô d·ªØ li·ªáu `training_data.json` hi·ªán t·∫°i c√≤n kh√° nh·ªè. B·∫°n c·∫ßn thu th·∫≠p th√™m nhi·ªÅu m·∫´u tin nh·∫Øn spam, l·ª´a ƒë·∫£o, v√† h·ª£p l·ªá trong th·ª±c t·∫ø ƒë·ªÉ model "h·ªçc" ƒë∆∞·ª£c nhi·ªÅu tr∆∞·ªùng h·ª£p h∆°n. D·ªØ li·ªáu c√†ng ƒëa d·∫°ng, model c√†ng th√¥ng minh.
    * **C√¢n b·∫±ng D·ªØ li·ªáu:** ƒê·∫£m b·∫£o s·ªë l∆∞·ª£ng tin nh·∫Øn trong c√°c l·ªõp `legitimate`, `spam`, `suspicious` kh√¥ng qu√° ch√™nh l·ªách nhau ƒë·ªÉ tr√°nh model b·ªã "thi√™n v·ªã".

* **Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n chuy√™n s√¢u (Advanced Text Preprocessing):**
    * **Word Segmentation (T√°ch t·ª´ ti·∫øng Vi·ªát):** C√°c th∆∞ vi·ªán nh∆∞ `vncorenlp` ho·∫∑c `underthesea` c√≥ th·ªÉ gi√∫p t√°ch t·ª´ ti·∫øng Vi·ªát ch√≠nh x√°c h∆°n, v√≠ d·ª• "khuy·∫ønm√£i" -> "khuy·∫øn m√£i". ƒêi·ªÅu n√†y gi√∫p `TfidfVectorizer` nh·∫≠n di·ªán t·ª´ ƒë√∫ng h∆°n.
    * **Lo·∫°i b·ªè Stopwords ti·∫øng Vi·ªát:** X√¢y d·ª±ng m·ªôt danh s√°ch c√°c t·ª´ d·ª´ng (stopword) ph·ªï bi·∫øn trong ti·∫øng Vi·ªát (v√≠ d·ª•: l√†, v√†, c·ªßa, c√≥,...) v√† lo·∫°i b·ªè ch√∫ng. ƒêi·ªÅu n√†y gi√∫p model t·∫≠p trung v√†o nh·ªØng t·ª´ mang nhi·ªÅu √Ω nghƒ©a h∆°n.
    * **Lemmatization/Stemming (ƒê∆∞a t·ª´ v·ªÅ d·∫°ng g·ªëc):** Chuy·ªÉn c√°c t·ª´ bi·∫øn th·ªÉ v·ªÅ c√πng m·ªôt d·∫°ng g·ªëc (v√≠ d·ª•: "vay", "vay m∆∞·ª£n" -> "vay").

* **Feature Engineering (T·∫°o th√™m ƒë·∫∑c tr∆∞ng):**
    * Thay v√¨ ch·ªâ d·ª±a v√†o n·ªôi dung vƒÉn b·∫£n, b·∫°n c√≥ th·ªÉ b·ªï sung c√°c "si√™u d·ªØ li·ªáu" (metadata) l√†m ƒë·∫∑c tr∆∞ng m·ªõi cho model, v√≠ d·ª•:
        * S·ªë l∆∞·ª£ng k√Ω t·ª± vi·∫øt hoa.
        * S·ªë l∆∞·ª£ng k√Ω t·ª± ƒë·∫∑c bi·ªát (!, @, #, $).
        * S·ª± hi·ªán di·ªán c·ªßa ƒë∆∞·ªùng link (URL).
        * S·ªë l∆∞·ª£ng s·ªë trong tin nh·∫Øn.

* **Tinh ch·ªânh si√™u tham s·ªë (Hyperparameter Tuning):**
    * S·ª≠ d·ª•ng c√°c k·ªπ thu·∫≠t nh∆∞ `GridSearchCV` c·ªßa scikit-learn ƒë·ªÉ t√¨m ra b·ªô tham s·ªë t·ªët nh·∫•t cho `TfidfVectorizer` (v√≠ d·ª•: `max_features`, `ngram_range`) v√† `MultinomialNB` (v√≠ d·ª•: `alpha`).

### 2. C·∫£i thi·ªán LLM Analyzer (L·ªõp ph√¢n t√≠ch s√¢u) üß†

L·ªõp n√†y x·ª≠ l√Ω c√°c ca kh√≥ m√† NB kh√¥ng ch·∫Øc ch·∫Øn.

* **Prompt Engineering (K·ªπ thu·∫≠t t·∫°o c√¢u l·ªánh):**
    * ƒê√¢y l√† c√°ch c·∫£i thi·ªán hi·ªáu qu·∫£ v√† √≠t t·ªën k√©m nh·∫•t. C√¢u l·ªánh (`prompt`) b·∫°n g·ª≠i cho LLM quy·∫øt ƒë·ªãnh r·∫•t nhi·ªÅu ƒë·∫øn ch·∫•t l∆∞·ª£ng c√¢u tr·∫£ l·ªùi.
    * **Th√™m v√≠ d·ª• (Few-shot learning):** Thay v√¨ ch·ªâ ƒë∆∞a ra ch·ªâ d·∫´n, h√£y cung c·∫•p cho LLM m·ªôt v√†i v√≠ d·ª• c·ª• th·ªÉ v·ªÅ tin nh·∫Øn spam/l·ª´a ƒë·∫£o v√† tin nh·∫Øn h·ª£p l·ªá ngay trong prompt.
    * **Y√™u c·∫ßu LLM "suy nghƒ© t·ª´ng b∆∞·ªõc" (Chain-of-thought):** Th√™m v√†o prompt y√™u c·∫ßu nh∆∞: *"H√£y ph√¢n t√≠ch tin nh·∫Øn t·ª´ng b∆∞·ªõc. ƒê·∫ßu ti√™n, x√°c ƒë·ªãnh √Ω ƒë·ªãnh ch√≠nh. Th·ª© hai, t√¨m c√°c d·∫•u hi·ªáu l·ª´a ƒë·∫£o. Cu·ªëi c√πng, ƒë∆∞a ra k·∫øt lu·∫≠n."* ƒêi·ªÅu n√†y gi√∫p LLM c√≥ qu√° tr√¨nh ph√¢n t√≠ch logic v√† ch√≠nh x√°c h∆°n.

* **S·ª≠ d·ª•ng Model LLM t·ªët h∆°n:**
    * C√°c model b·∫°n ƒëang d√πng l√† c√°c l·ª±a ch·ªçn mi·ªÖn ph√≠ ho·∫∑c gi√° r·∫ª (`gpt-3.5-turbo`, `llama-3.3-70b-instruct:free`). N·∫øu ng√¢n s√°ch cho ph√©p, vi·ªác n√¢ng c·∫•p l√™n c√°c model m·∫°nh h∆°n nh∆∞ **GPT-4o** ho·∫∑c c√°c phi√™n b·∫£n Llama tr·∫£ ph√≠ c√≥ th·ªÉ c·∫£i thi·ªán ƒë√°ng k·ªÉ ƒë·ªô ch√≠nh x√°c.

* **K·∫øt h·ª£p Heuristics (Lu·∫≠t suy nghi·ªám):**
    * Th√™m m·ªôt v√†i lu·∫≠t ƒë∆°n gi·∫£n ƒë·ªÉ x·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p c·ª±c k·ª≥ r√µ r√†ng **tr∆∞·ªõc khi** g·ªçi LLM ƒë·ªÉ ti·∫øt ki·ªám chi ph√≠. V√≠ d·ª•:
        * N·∫øu tin nh·∫Øn ch·ª©a m·ªôt s·ªë ƒëi·ªán tho·∫°i trong danh s√°ch ƒëen (blacklist).
        * N·∫øu tin nh·∫Øn ch·ª©a m·ªôt ƒë∆∞·ªùng link ƒë√£ ƒë∆∞·ª£c x√°c ƒë·ªãnh l√† ƒë·ªôc h·∫°i.

---

### ## T√≥m t·∫Øt v√† L·ªô tr√¨nh ƒë·ªÅ xu·∫•t

1.  **Ng·∫Øn h·∫°n (D·ªÖ th·ª±c hi·ªán):**
    * B·∫Øt ƒë·∫ßu **thu th·∫≠p th√™m d·ªØ li·ªáu** hu·∫•n luy·ªán cho Naive Bayes.
    * **C·∫£i thi·ªán prompt** cho LLM b·∫±ng c√°ch th√™m v√≠ d·ª• (few-shot).
    * Th√™m b∆∞·ªõc **t√°ch t·ª´ ti·∫øng Vi·ªát** v√†o quy tr√¨nh ti·ªÅn x·ª≠ l√Ω c·ªßa Naive Bayes.

2.  **Trung h·∫°n:**
    * **B·ªï sung Feature Engineering** (ƒë·∫øm k√Ω t·ª± vi·∫øt hoa, link,...).
    * S·ª≠ d·ª•ng **GridSearchCV** ƒë·ªÉ tinh ch·ªânh tham s·ªë cho Naive Bayes.
    * X√¢y d·ª±ng m·ªôt v√†i **lu·∫≠t Heuristics** ƒë∆°n gi·∫£n.

3.  **D√†i h·∫°n:**
    * Th·ª≠ nghi·ªám v·ªõi c√°c **model LLM tr·∫£ ph√≠** m·∫°nh h∆°n.
    * X√¢y d·ª±ng m·ªôt h·ªá th·ªëng ƒë·ªÉ ng∆∞·ªùi d√πng c√≥ th·ªÉ "b√°o c√°o" (report) tin nh·∫Øn sai, t·ª´ ƒë√≥ li√™n t·ª•c c·∫≠p nh·∫≠t v√† hu·∫•n luy·ªán l·∫°i (re-train) model Naive Bayes.
	
	